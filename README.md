# ğŸ¦™ RAG with LlamaIndex and Groq

This project demonstrates a simple yet powerful Retrieval-Augmented Generation (RAG) setup using [LlamaIndex](https://www.llamaindex.ai/), [Groq LLM](https://groq.com/), and HuggingFace Embeddings.

> âœ… Notebook ready for Colab with one-click access.

---


## ğŸ““ Chatwithdoc.ipynb

- Install and use LlamaIndex with Groq LLM integration.
- Embed and index documents using HuggingFace embeddings.
- Run conversational RAG using Groq's high-speed inference.

### ğŸš€ Try on Colab

You can launch the notebook directly on Google Colab using the badge below:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Baishaki-sfdc/RAG-llamaindex-groq/blob/main/Chatwithdoc.ipynb)

---

## ğŸ“¦ Installation

Install all required dependencies using the following pip command:

```bash
pip install llama-index==0.10.18 \
            llama-index-llms-groq==0.1.3 \
            groq==0.4.2 \
            llama-index-embeddings-huggingface==0.2.0


 Features
ğŸ” Document loading and indexing

ğŸ§  Embedding via HuggingFace models

âš¡ Conversational AI using Groq LLM

ğŸ“ RAG (Retrieval-Augmented Generation) for chat



âœ… Compatibility
Tested with:

Python 3.11

Google Colab



